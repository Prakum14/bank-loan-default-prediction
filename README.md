# bank-loan-default-prediction
It predicts whether a borrower applying for a loan can default on loan or not possibly

Project Overview

This project focuses on building a robust Machine Learning model to predict the likelihood of a borrower defaulting on a bank loan. This is a critical binary classification task for financial institutions, aimed at improving risk assessment and minimizing potential financial losses.

The primary objective is to maximize the prediction accuracy (typically measured by AUC) of the binary target variable, loan_paid_back (1.0 for paid, 0.0 for default).

üöÄ Repository Structure

The repository is structured following standard ML project best practices, separating code, data, models, and configuration files.

Directory/File         Description

data/raw/             Contains the raw input files: train.csv and test.csv.

data/processed/       Directory for intermediate, cleaned data files (generated by data_processor.py).

src/                  Source Code: Core Python scripts for feature engineering and model training.

src/data_processor.py  Handles data loading, cleaning, feature creation, and preprocessing (encoding/scaling).

src/model_trainer.py  Contains the logic for initializing, training, and evaluating the final model.

src/pipeline.py        The main execution script that orchestrates the entire ML workflow.

models/               Directory to store the trained, serialized model files (e.g., .pkl or .joblib).

notebooks/           Contains exploratory data analysis (EDA) and initial model prototyping notebooks (e.g., the original Kaggle notebook).

.github/workflows/   Configuration for GitHub Actions (CI/CD).

requirements.txt     Lists all necessary Python dependencies.

‚öôÔ∏è Setup and Execution

To set up the environment and run the complete training pipeline:

1. Clone the Repository

git clone [https://github.com/your-username/bank-loan-default-prediction.git](https://github.com/your-username/bank-loan-default-prediction.git)
cd bank-loan-default-prediction


2. Install Dependencies

Ensure you have Python (3.8+) installed. All required libraries are listed in requirements.txt.

pip install -r requirements.txt


3. Run the Training Pipeline

Execute the main script. This will load the raw data, perform feature engineering, train the model, and save the resulting predictions and the trained model artifact.

python src/pipeline.py


ü§ñ CI/CD Workflow (GitHub Actions)

This project utilizes GitHub Actions for Continuous Integration. The workflow (.github/workflows/ci.yml) is triggered on every push to the main or master branch.

The CI pipeline performs the following steps:

Sets up the Python environment.

Installs all dependencies from requirements.txt.

Executes src/pipeline.py to ensure the entire data processing and model training workflow runs successfully without errors.

This ensures that the main training pipeline is always operational and reproducible.

üìä Results Summary

(Note: Replace the following with your actual best metric and model)

The final production model uses Random Forest (RF) classification, optimized for handling imbalanced data through custom loss weighting.

Metric          Score

ROC AUC        0.765 (Example Score)

Model          Optimized Random Forest Classifier

Key Features   credit_score, Income-to-Debt Ratio (Engineered Feature)

Next Steps:

Implement advanced ensemble methods (e.g., XGBoost or CatBoost).

Add unit tests (tests/test_features.py) for data quality and feature engineering steps.
